{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 2\n",
    "\n",
    "- Build and train a MLP Model to classify Mnist dataset\n",
    "\n",
    " 1- MLP Network accepts 1D data. So we should flatten our 2D image, then print the dimension of the result arrays.\n",
    " \n",
    " 2- Normalize data by rescaling them to (0,1) \n",
    " \n",
    " 3- Convert label arrays to 1-hot representation (`keras.utils.to_categorical`)\n",
    " \n",
    " 4- Define Model\n",
    "    * Hidden Layer 1: Fully Conncted + Relu Activition (e.g. 512 Nuerons)\n",
    "    * Hidden Layer 2: Fully Connected + Relu Activition (e.g. 512 Neurons)\n",
    "    * Outout Layer: Fully Connected + Softmax Activition\n",
    " \n",
    " \n",
    "- Build and train a CNN+MLP deep learning model with Keras with followings specs for MNIST dataset:\n",
    "\n",
    "    1. Conv2D(32, kernel_size=(3, 3), activation='relu')\n",
    "    2. Conv2D(64, kernel_size=(3, 3), activation='relu')\n",
    "    3. MaxPooling2D(pool_size=(2, 2))\n",
    "    4. Dense(128, activation='relu')\n",
    "    5. Dense(num_classes, activation='softmax')\n",
    "\n",
    "    Also build another model with BatchNormalization and Dropout.\n",
    "    Compare these two CNN + MLP models performance for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import RMSprop, SGD\n",
    "from keras.initializers import RandomNormal\n",
    "from tensorflow.keras import utils\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 9s 142us/step - loss: 0.2469 - accuracy: 0.9232 - val_loss: 0.1184 - val_accuracy: 0.9616\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 8s 141us/step - loss: 0.1022 - accuracy: 0.9693 - val_loss: 0.0869 - val_accuracy: 0.9747\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 9s 149us/step - loss: 0.0758 - accuracy: 0.9773 - val_loss: 0.0790 - val_accuracy: 0.9770\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.0591 - accuracy: 0.9821 - val_loss: 0.0843 - val_accuracy: 0.9772\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.0514 - accuracy: 0.9849 - val_loss: 0.0681 - val_accuracy: 0.9827\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.0423 - accuracy: 0.9868 - val_loss: 0.0743 - val_accuracy: 0.9820\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.0372 - accuracy: 0.9891 - val_loss: 0.0849 - val_accuracy: 0.9827\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.0335 - accuracy: 0.9899 - val_loss: 0.0849 - val_accuracy: 0.9803\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.0313 - accuracy: 0.9908 - val_loss: 0.0848 - val_accuracy: 0.9825\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.0282 - accuracy: 0.9921 - val_loss: 0.0900 - val_accuracy: 0.9818\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 11s 176us/step - loss: 0.0270 - accuracy: 0.9920 - val_loss: 0.0934 - val_accuracy: 0.9823\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.0262 - accuracy: 0.9930 - val_loss: 0.0862 - val_accuracy: 0.9836\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 0.0241 - accuracy: 0.9934 - val_loss: 0.0900 - val_accuracy: 0.9841\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.0209 - accuracy: 0.9941 - val_loss: 0.0980 - val_accuracy: 0.9830\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 11s 179us/step - loss: 0.0208 - accuracy: 0.9942 - val_loss: 0.1189 - val_accuracy: 0.9823\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 10s 169us/step - loss: 0.0202 - accuracy: 0.9946 - val_loss: 0.1265 - val_accuracy: 0.9803\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.0200 - accuracy: 0.9947 - val_loss: 0.1158 - val_accuracy: 0.9827\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.0188 - accuracy: 0.9950 - val_loss: 0.1222 - val_accuracy: 0.9829\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.0194 - accuracy: 0.9953 - val_loss: 0.1204 - val_accuracy: 0.9826\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 10s 174us/step - loss: 0.0164 - accuracy: 0.9956 - val_loss: 0.1172 - val_accuracy: 0.9843\n",
      "Test loss: 0.117173307576248\n",
      "Test accuracy: 0.9843000173568726\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import matplotlib.pyplot as plt #This package is for plotting\n",
    "%matplotlib inline  \n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "from keras.optimizers import SGD\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.models import load_model\n",
    "import os\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Reshape x_train and x_test\n",
    "x_train = np.reshape(x_train,[-1, 28*28])\n",
    "x_test = np.reshape(x_test,[-1, 28*28])\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/np.max(x_train)\n",
    "x_test = x_test/np.max(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "# Add the layers to model here.\n",
    "model2.add(Dense(512, activation='relu', input_shape=(784,), kernel_initializer= RandomNormal(0,0.01)))\n",
    "model2.add(Dense(512, activation='relu', kernel_initializer= RandomNormal(0,0.01)))\n",
    "model2.add(Dense(10, activation='softmax', kernel_initializer= RandomNormal(0,0.01)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.01)\n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "             optimizer=sgd,\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()\n",
    "# Here we saved the raw model without any training. we will use it later.\n",
    "model2.save('raw_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label: 5\n",
      "Predicted label: 5\n"
     ]
    }
   ],
   "source": [
    "# reload the model here:\n",
    "model2 = load_model('raw_model.h5')\n",
    "# generate a random number. (use numpy random.randint)\n",
    "rand_num = np.random.randint(60000)\n",
    "img = x_train[rand_num]\n",
    "img = np.expand_dims(img, axis = 0)\n",
    "predicted_label =model.predict(img, 1)\n",
    "img = np.reshape(img,(28,28))\n",
    "plt.imshow(img, cmap='gray' )\n",
    "plt.show()\n",
    "# print its label\n",
    "true_label = np.argmax(y_train[rand_num])\n",
    "predicted_label = np.argmax(predicted_label)\n",
    "print('True label:', true_label)\n",
    "print('Predicted label:', predicted_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data dim: (60000, 28, 28)\n",
      "test data dim: (10000, 28, 28)\n",
      "test label dim: (10000,)\n",
      "max of training data: 255\n"
     ]
    }
   ],
   "source": [
    "# Loading the data\n",
    "\n",
    "(dx_train, dy_train), (dx_test, dy_test) = mnist.load_data()\n",
    "\n",
    "print('train data dim:', dx_train.shape)\n",
    "print('test data dim:', dx_test.shape)\n",
    "print('test label dim:', dy_test.shape)\n",
    "\n",
    "print('max of training data:', np.max(dx_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "# input\n",
    "model3.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(28, 28, 1)))\n",
    "# - hidden layers -\n",
    "model3.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(128, activation='relu'))\n",
    "# model.add(Flatten())\n",
    "# output\n",
    "model3.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model3.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n",
      "(28, 28)\n",
      "()\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "print(dx_train[0].shape)\n",
    "print(dx_train[1].shape)\n",
    "print(dy_train[0].shape)\n",
    "print(dy_test[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n",
      "(28, 28, 1)\n",
      "(10,)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "img_rows, img_cols = 28, 28\n",
    "dx_train = dx_train.reshape(dx_train.shape[0], img_rows, img_cols, 1)\n",
    "dx_test = dx_test.reshape(dx_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "# change categories to one-hot\n",
    "dy_train = utils.to_categorical(dy_train, 10)\n",
    "dy_test = utils.to_categorical(dy_test, 10)\n",
    "\n",
    "print(dx_train[0].shape)\n",
    "print(dx_train[1].shape)\n",
    "print(dy_train[0].shape)\n",
    "print(dy_test[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 90s 1ms/step - loss: 0.3470 - accuracy: 0.9577 - val_loss: 0.0623 - val_accuracy: 0.9808\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 91s 2ms/step - loss: 0.0500 - accuracy: 0.9845 - val_loss: 0.0741 - val_accuracy: 0.9791\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 100s 2ms/step - loss: 0.0357 - accuracy: 0.9888 - val_loss: 0.0443 - val_accuracy: 0.9867\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 94s 2ms/step - loss: 0.0271 - accuracy: 0.9916 - val_loss: 0.0611 - val_accuracy: 0.9855\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 105s 2ms/step - loss: 0.0265 - accuracy: 0.9919 - val_loss: 0.0688 - val_accuracy: 0.9821\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 98s 2ms/step - loss: 0.0184 - accuracy: 0.9945 - val_loss: 0.0668 - val_accuracy: 0.9847\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 93s 2ms/step - loss: 0.0158 - accuracy: 0.9952 - val_loss: 0.0683 - val_accuracy: 0.9857\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 99s 2ms/step - loss: 0.0153 - accuracy: 0.9956 - val_loss: 0.0988 - val_accuracy: 0.9840\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 94s 2ms/step - loss: 0.0167 - accuracy: 0.9957 - val_loss: 0.0857 - val_accuracy: 0.9850\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 97s 2ms/step - loss: 0.0098 - accuracy: 0.9971 - val_loss: 0.0931 - val_accuracy: 0.9856\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "history3 = model3.fit(x=dx_train, y=dy_train,\n",
    "                   batch_size = 32,\n",
    "                   epochs = 10,\n",
    "                   verbose = 1,\n",
    "                   validation_data=(dx_test, dy_test))\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,200,778\n",
      "Trainable params: 1,200,330\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPool2D, Flatten\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.layers import BatchNormalization, Dropout\n",
    "\n",
    "model4 = Sequential()\n",
    "model4.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(28, 28, 1)))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model4.add(Dropout(0.25))\n",
    "model4.add(Flatten())\n",
    "model4.add(Dense(128, activation='relu'))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(Dropout(0.5))\n",
    "model4.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model4.compile(loss=categorical_crossentropy,\n",
    "              optimizer=Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model4.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 361s 6ms/step - loss: 0.1511 - accuracy: 0.9546 - val_loss: 0.0490 - val_accuracy: 0.9842\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 341s 6ms/step - loss: 0.0644 - accuracy: 0.9811 - val_loss: 0.0357 - val_accuracy: 0.9873\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 326s 5ms/step - loss: 0.0495 - accuracy: 0.9851 - val_loss: 0.0328 - val_accuracy: 0.9897\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 306s 5ms/step - loss: 0.0428 - accuracy: 0.9874 - val_loss: 0.0307 - val_accuracy: 0.9888\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 296s 5ms/step - loss: 0.0362 - accuracy: 0.9888 - val_loss: 0.0291 - val_accuracy: 0.9891\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 311s 5ms/step - loss: 0.0309 - accuracy: 0.9902 - val_loss: 0.0272 - val_accuracy: 0.9906\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 292s 5ms/step - loss: 0.0296 - accuracy: 0.9908 - val_loss: 0.0361 - val_accuracy: 0.9891\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 292s 5ms/step - loss: 0.0247 - accuracy: 0.9922 - val_loss: 0.0323 - val_accuracy: 0.9900\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 300s 5ms/step - loss: 0.0218 - accuracy: 0.9931 - val_loss: 0.0277 - val_accuracy: 0.9904\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 377s 6ms/step - loss: 0.0198 - accuracy: 0.9938 - val_loss: 0.0291 - val_accuracy: 0.9917\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training the model\n",
    "history4 = model4.fit(x=dx_train, y=dy_train,\n",
    "                   batch_size = 32,\n",
    "                   epochs = 10,\n",
    "                   verbose = 1,\n",
    "                   validation_data=(dx_test, dy_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

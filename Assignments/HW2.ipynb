{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 2\n",
    "\n",
    "- Build and train a MLP Model to classify Mnist dataset\n",
    "\n",
    " 1- MLP Network accepts 1D data. So we should flatten our 2D image, then print the dimension of the result arrays.\n",
    " \n",
    " 2- Normalize data by rescaling them to (0,1) \n",
    " \n",
    " 3- Convert label arrays to 1-hot representation (`keras.utils.to_categorical`)\n",
    " \n",
    " 4- Define Model\n",
    "    * Hidden Layer 1: Fully Conncted + Relu Activition (e.g. 512 Nuerons)\n",
    "    * Hidden Layer 2: Fully Connected + Relu Activition (e.g. 512 Neurons)\n",
    "    * Outout Layer: Fully Connected + Softmax Activition\n",
    " \n",
    " \n",
    "- Build and train a CNN+MLP deep learning model with Keras with followings specs for MNIST dataset:\n",
    "\n",
    "    1. Conv2D(32, kernel_size=(3, 3), activation='relu')\n",
    "    2. Conv2D(64, kernel_size=(3, 3), activation='relu')\n",
    "    3. MaxPooling2D(pool_size=(2, 2))\n",
    "    4. Dense(128, activation='relu')\n",
    "    5. Dense(num_classes, activation='softmax')\n",
    "\n",
    "    Also build another model with BatchNormalization and Dropout.\n",
    "    Compare these two CNN + MLP models performance for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import RMSprop, SGD\n",
    "from keras.initializers import RandomNormal\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 5s 0us/step\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 8s 134us/step - loss: 0.2448 - accuracy: 0.9258 - val_loss: 0.0942 - val_accuracy: 0.9700\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 8s 128us/step - loss: 0.1008 - accuracy: 0.9696 - val_loss: 0.0942 - val_accuracy: 0.9707\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 8s 133us/step - loss: 0.0742 - accuracy: 0.9776 - val_loss: 0.0754 - val_accuracy: 0.9791\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.0613 - accuracy: 0.9809 - val_loss: 0.0729 - val_accuracy: 0.9811\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 8s 131us/step - loss: 0.0498 - accuracy: 0.9850 - val_loss: 0.0629 - val_accuracy: 0.9842\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 8s 135us/step - loss: 0.0425 - accuracy: 0.9868 - val_loss: 0.0852 - val_accuracy: 0.9808\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 8s 137us/step - loss: 0.0386 - accuracy: 0.9883 - val_loss: 0.0805 - val_accuracy: 0.9826\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 8s 138us/step - loss: 0.0336 - accuracy: 0.9903 - val_loss: 0.0935 - val_accuracy: 0.9816\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 8s 136us/step - loss: 0.0317 - accuracy: 0.9904 - val_loss: 0.0780 - val_accuracy: 0.9839\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 8s 137us/step - loss: 0.0287 - accuracy: 0.9916 - val_loss: 0.0987 - val_accuracy: 0.9821\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 8s 137us/step - loss: 0.0264 - accuracy: 0.9924 - val_loss: 0.0960 - val_accuracy: 0.9822\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 9s 147us/step - loss: 0.0261 - accuracy: 0.9928 - val_loss: 0.0924 - val_accuracy: 0.9841\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 9s 153us/step - loss: 0.0242 - accuracy: 0.9935 - val_loss: 0.1010 - val_accuracy: 0.9838\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.0205 - accuracy: 0.9940 - val_loss: 0.1121 - val_accuracy: 0.9832\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.0213 - accuracy: 0.9941 - val_loss: 0.1170 - val_accuracy: 0.9817\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.0209 - accuracy: 0.9945 - val_loss: 0.1101 - val_accuracy: 0.9840\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 9s 143us/step - loss: 0.0201 - accuracy: 0.9948 - val_loss: 0.1118 - val_accuracy: 0.9821\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 9s 143us/step - loss: 0.0183 - accuracy: 0.9945 - val_loss: 0.1296 - val_accuracy: 0.9831\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 9s 147us/step - loss: 0.0195 - accuracy: 0.9951 - val_loss: 0.1190 - val_accuracy: 0.9842\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 9s 149us/step - loss: 0.0170 - accuracy: 0.9953 - val_loss: 0.1144 - val_accuracy: 0.9833\n",
      "Test loss: 0.1143702071092662\n",
      "Test accuracy: 0.983299970626831\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import matplotlib.pyplot as plt #This package is for plotting\n",
    "%matplotlib inline  \n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "from keras.optimizers import SGD\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.models import load_model\n",
    "import os\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Reshape x_train and x_test\n",
    "x_train = np.reshape(x_train,[-1, 28*28])\n",
    "x_test = np.reshape(x_test,[-1, 28*28])\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/np.max(x_train)\n",
    "x_test = x_test/np.max(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# Add the layers to model here.\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,), kernel_initializer= RandomNormal(0,0.01)))\n",
    "model.add(Dense(512, activation='relu', kernel_initializer= RandomNormal(0,0.01)))\n",
    "model.add(Dense(10, activation='softmax', kernel_initializer= RandomNormal(0,0.01)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer=sgd,\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "# Here we saved the raw model without any training. we will use it later.\n",
    "model.save('raw_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label: 3\n",
      "Predicted label: 6\n"
     ]
    }
   ],
   "source": [
    "# reload the model here:\n",
    "model = load_model('raw_model.h5')\n",
    "# generate a random number. (use numpy random.randint)\n",
    "rand_num = np.random.randint(60000)\n",
    "img = x_train[rand_num]\n",
    "img = np.expand_dims(img, axis = 0)\n",
    "predicted_label =model.predict(img, 1)\n",
    "img = np.reshape(img,(28,28))\n",
    "plt.imshow(img, cmap='gray' )\n",
    "plt.show()\n",
    "# print its label\n",
    "true_label = np.argmax(y_train[rand_num])\n",
    "predicted_label = np.argmax(predicted_label)\n",
    "print('True label:', true_label)\n",
    "print('Predicted label:', predicted_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

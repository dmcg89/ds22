{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network (CNN)\n",
    "\n",
    "- CNN is basically two dimensional configuration of neural networks\n",
    "\n",
    "- The input of CNN are image (3 N by N if it color image and N by N if its black and white image)\n",
    "\n",
    "- The weights are also two dimensional array\n",
    "\n",
    "<img src=\"rgb_image.png\" width=\"300\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The weights in CNN\n",
    "\n",
    "- The weights in CNN are called:\n",
    "\n",
    "    - Kernel \n",
    "    \n",
    "    or    \n",
    "    \n",
    "    - Filter matrix\n",
    "    \n",
    "    \n",
    "<img src=\"kernel_image.png\" width=\"400\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stride\n",
    "\n",
    "- To define a CNN, we should specify the horizontal and vertical movement steps \n",
    "\n",
    "- what is the output size with stride = 1 and stride =2?\n",
    "\n",
    "<img src=\"stride_1.png\" width=\"400\" height=\"400\">\n",
    "\n",
    "<img src=\"stride_2.png\" width=\"400\" height=\"400\">\n",
    "\n",
    "- output_size = (input_size - filter_size)/stride + 1\n",
    "\n",
    "- Stride visualization: http://deeplearning.stanford.edu/wiki/index.php/Feature_extraction_using_convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(32, kernel_size=(3, 3), strides=(1, 1), activation='relu', input_shape=input_shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max Pooling vs Average Pooling\n",
    "\n",
    "- Max pooling: take the maximum element from each window of a certain size\n",
    "\n",
    "<img src=\"maxpooling.png\" width=\"400\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faltten Layer \n",
    "\n",
    "- After feature extraction that is done by multiple Convolutional layers, we use flatten layer to add MLP after convolutional layers in order to do classification task\n",
    "\n",
    "- This one is simple--it's just Keras's verison of numpy.reshape. This reshapes n-dimensional arrays to a vector. This is necessary when moving from Conv2D layers, which expect 2-dimensional arrays as inputs, to Dense layers, which expect 1-dimension vectors as inputs. As a concrete example, a Flatten layer given a 28 x 28 array as input would output a vector of the shape (784, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the whole NN: CNN + MLP\n",
    "\n",
    "<img src=\"CNN.png\" width=\"600\" height=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity: Obtain the number of parameters for the following CNN\n",
    "\n",
    "- By default, the strides = (1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miladtoutounchian/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(28, 28, 1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "- output_size = (28 - 3)/1 + 1 = 26\n",
    "\n",
    "- output_size = (26 - 3)/1 + 1 = 24\n",
    "\n",
    "- The parameters for the first Conv2D = 32 x 9 + 32 = 320\n",
    "\n",
    "- The parameters for the second Conv2D = 64 x 32 x 9 + 64 = 18496\n",
    "\n",
    "- The shape for flatten is: 12 x 12 x 64 = 9216\n",
    "\n",
    "- The parameters for dense_1 = 9216 x 128 + 128 = 1179776\n",
    "\n",
    "- The parameters for dense_2 = 128 x 10 + 10 = 1290"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation for CNN\n",
    "\n",
    "- Suppose we want to feed a 4 by 4 image to a CNN network, how we should reshape the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miladtoutounchian/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5]\n",
      " [12]\n",
      " [ 1]\n",
      " [ 8]]\n",
      "[[[ 5]\n",
      "  [12]\n",
      "  [ 1]\n",
      "  [ 8]]\n",
      "\n",
      " [[ 2]\n",
      "  [10]\n",
      "  [ 3]\n",
      "  [ 6]]\n",
      "\n",
      " [[ 4]\n",
      "  [ 7]\n",
      "  [ 9]\n",
      "  [ 1]]\n",
      "\n",
      " [[ 5]\n",
      "  [ 7]\n",
      "  [ 5]\n",
      "  [ 6]]]\n",
      "[[[[0.         0.30877003 0.        ]\n",
      "   [0.         1.240459   0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.83486694 1.7766566  0.        ]]]]\n",
      "M :\n",
      "[[[0.         0.30877003]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[1.240459   0.        ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.         0.83486694]\n",
      "  [1.7766566  0.        ]]]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 4, 4, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 3, 3, 2)           10        \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 2, 2, 3)           27        \n",
      "=================================================================\n",
      "Total params: 37\n",
      "Trainable params: 37\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "input_img = Input(shape=(4, 4, 1))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "x = Conv2D(2, (2, 2), activation='relu')(input_img)\n",
    "y = Conv2D(3, (2, 2), activation='relu')(x)\n",
    "model = Model(input_img, y)\n",
    "# cnv_ml_1 = Model(input_img, x)\n",
    "\n",
    "data = np.array([[5, 12, 1, 8], [2, 10, 3, 6], [4, 7, 9, 1], [5, 7, 5, 6]])\n",
    "data = data.reshape(4, 4, 1)\n",
    "print(data[0])\n",
    "data = np.expand_dims(data, axis=0)\n",
    "# data = data.reshape(4, 4, 1)\n",
    "print(data[0])\n",
    "print(model.predict(data))\n",
    "print('M :')\n",
    "print(model.predict(data).reshape(3, 2, 2))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.         3.6707969  0.        ]\n",
      "   [0.         0.         3.1801198 ]]\n",
      "\n",
      "  [[0.         1.1546224  0.6197593 ]\n",
      "   [0.         0.13880396 1.9919777 ]]]]\n",
      "M :\n",
      "[[[0.         3.6707969 ]\n",
      "  [0.         0.        ]]\n",
      "\n",
      " [[0.         3.1801198 ]\n",
      "  [0.         1.1546224 ]]\n",
      "\n",
      " [[0.6197593  0.        ]\n",
      "  [0.13880396 1.9919777 ]]]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 4, 4, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 2)           10        \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 2, 2, 3)           27        \n",
      "=================================================================\n",
      "Total params: 37\n",
      "Trainable params: 37\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "input_img = Input(shape=(4, 4, 1))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "x = Conv2D(2, (2, 2), activation='relu')(input_img)\n",
    "y = Conv2D(3, (2, 2), activation='relu')(x)\n",
    "model = Model(input_img, y)\n",
    "# cnv_ml_1 = Model(input_img, x)\n",
    "\n",
    "data = np.array([[5, 12, 1, 8], [2, 10, 3, 6], [4, 7, 9, 1], [5, 7, 5, 6]])\n",
    "data = data.reshape(1, 4, 4, 1)\n",
    "print(model.predict(data))\n",
    "print('M :')\n",
    "print(model.predict(data).reshape(3, 2, 2))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "img_rows, img_cols = 28, 28 \n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "    \n",
    "print(x_train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
